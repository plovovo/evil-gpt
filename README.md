# evil-gpt

The idea is to create a GPT-like LLM that will be rude and sarcastic. The model should provide the actual, requested answer for a textual content query, however wrap it in extremely impolite statements. 
Main problem: lack of proper amount of good quality data to train the model.
Possible benefits: stream/group chat integration; also might help train models to handle toxic or adversarial language by testing how well systems can deal with rudeness while staying helpful and non-reactive.
